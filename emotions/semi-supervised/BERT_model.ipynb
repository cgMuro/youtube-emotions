{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "source": [
    "# Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/youtube-sentiments/youtube_labeled_edited.csv', usecols=['text', 'emotion'])\n",
    "\n",
    "df"
   ]
  },
  {
   "source": [
    "# Process Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text']\n",
    "y = df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of emotions to classify\n",
    "EMOTIONS = df['emotion'].unique()\n",
    "N_EMOTIONS = len(EMOTIONS)\n",
    "N_EMOTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = {\n",
    "    0: 'constructive feedback/idea',\n",
    "    1: 'negative',\n",
    "    2: 'neutral/other', \n",
    "    3: 'positive', \n",
    "    4: 'sadness', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode classes\n",
    "y = y.apply(lambda example: [k for k, v in decode_map.items() if v == example][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "source": [
    "### Tokenizer and Encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased', use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode data\n",
    "X_train_encoded = tokenizer(X_train.to_list(), truncation=True, padding=True, return_tensors=\"pt\")\n",
    "X_test_encoded = tokenizer(X_test.to_list(), truncation=True, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "source": [
    "### Training and Testing Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "train_data = torch.utils.data.TensorDataset(\n",
    "    X_train_encoded['input_ids'], \n",
    "    X_train_encoded['attention_mask'],\n",
    "    torch.tensor(y_train)\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Testing Data\n",
    "test_data = torch.utils.data.TensorDataset(\n",
    "    X_test_encoded['input_ids'], \n",
    "    X_test_encoded['attention_mask'],\n",
    "    torch.tensor(y_test.to_list())\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=8,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=N_EMOTIONS)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty CUDA cache\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_summary(device=device, abbreviated=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "EPOCHS = 1\n",
    "\n",
    "# Model on training mode\n",
    "model.train()\n",
    "# Define optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader)*EPOCHS)\n",
    "\n",
    "# Training loop\n",
    "print('Training...\\n')\n",
    "for epoch in range(EPOCHS):\n",
    "    print('-'*100)\n",
    "    print('Epoch:', epoch+1)\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # Zero model gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Get input data and move them to device\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        # Predict\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        # Get loss, calculate and clip gradients, and update parameters\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print('Loss:', avg_train_loss)\n",
    "    print('-'*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "source": [
    "# Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model on CUDA\n",
    "model = model.to(device)\n",
    "# Model on evaluation mode\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        # Get data and move them to the right device\n",
    "        text, attention, labels = data\n",
    "        text, attention, labels = text.to(device), attention.to(device), labels.to(device)\n",
    "        # Get predictions from model\n",
    "        outputs = model(text, attention)\n",
    "        # Store predictions for batch size\n",
    "        predictions = []\n",
    "        for output in outputs.logits:\n",
    "            _, predicted = torch.max(outputs.logits[0], 0)\n",
    "            predictions.append(predicted.item())\n",
    "        predictions = torch.tensor(predictions).to(device)\n",
    "        # Calculate total\n",
    "        total += labels.size(0)\n",
    "        # Calculate number of correct classification\n",
    "        correct += (predictions == labels).sum().item()\n",
    "\n",
    "print(f'Testing accuracy: {(100 * correct / total)}%')"
   ]
  },
  {
   "source": [
    "# New Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"\n",
    "    Programming is yelling at a computer what to do in a made-up cyberlanguage and the computer ignoring what you said because you missed a comma.\n",
    "\"\"\"\n",
    "\n",
    "encoded_sentence = tokenizer(sentence, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(encoded_sentence.input_ids, encoded_sentence.attention_mask)\n",
    "    prediction = np.argmax(prediction.logits)\n",
    "\n",
    "decode_map[prediction.item()]"
   ]
  },
  {
   "source": [
    "# Save Model and Tokenizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('/tmp/model')\n",
    "tokenizer.save_pretrained('/tmp/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
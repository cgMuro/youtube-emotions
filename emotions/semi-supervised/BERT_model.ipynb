{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMETERS_TUNING = False\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "source": [
    "# Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/youtube-sentiments/youtube_labeled_edited.csv', usecols=['text', 'emotion'])\n",
    "\n",
    "df"
   ]
  },
  {
   "source": [
    "# Process Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text']\n",
    "y = df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of emotions to classify\n",
    "EMOTIONS = df['emotion'].unique()\n",
    "N_EMOTIONS = len(EMOTIONS)\n",
    "N_EMOTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = {\n",
    "    0: 'constructive feedback/idea',\n",
    "    1: 'negative',\n",
    "    2: 'neutral/other', \n",
    "    3: 'positive', \n",
    "    4: 'sadness', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode classes\n",
    "y = y.apply(lambda example: [k for k, v in decode_map.items() if v == example][0])"
   ]
  },
  {
   "source": [
    "### SMOTE Oversample and random undersample\n",
    "\n",
    "https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define pipeline\n",
    "# over = SMOTE(sampling_strategy=0.1)\n",
    "# under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "# steps = [('o', over), ('u', under)]\n",
    "# pipeline = Pipeline(steps=steps)\n",
    "# # Transform dataset\n",
    "# x, y = pipeline.fit_resample(x, y)"
   ]
  },
  {
   "source": [
    "### Split data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "source": [
    "### Text Augmentantion\n",
    "* Spelling Augmenter\n",
    "* Contextual Word Embeddings Augmenter\n",
    "* Synonym Augmenter\n",
    "* Antonym Augmenter\n",
    "* Random Word Augmenter\n",
    "* Contextual Word Embeddings for Sentence Augmenter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas"
   ]
  },
  {
   "source": [
    "1. Character Augmenters (augmenters that work on character level)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyboard Augmenter\n",
    "def keyboard_augmenter(text):\n",
    "    print('Keyboard Augmenter...')\n",
    "    # substitute word by spelling mistake words dictionary\n",
    "    aug = naw.SpellingAug()\n",
    "    spelling_aug = aug.augment(text, n=3)\n",
    "    return spelling_aug"
   ]
  },
  {
   "source": [
    "2. Word Augmenters (augmenters that work on word level)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spelling Augmenter #\n",
    "# Substitute word by spelling mistake words dictionary\n",
    "def spelling_augmenter(text):\n",
    "    print('Spelling Augmenter...')\n",
    "    aug = naw.SpellingAug()\n",
    "    spelling_aug = aug.augment(text, n=3)\n",
    "    return spelling_aug\n",
    "\n",
    "# Contextual Word Embeddings Augmenter #\n",
    "# Insert word by contextual word embeddings\n",
    "def insert_contextual_word_embeddings_augmenter(text):\n",
    "    print('Insert Contextual Word Embeddings Augmenter...')\n",
    "    context = naw.ContextualWordEmbsAug(\n",
    "        model_path='bert-base-uncased', action=\"insert\"\n",
    "    )\n",
    "    res = context.augment(text)\n",
    "    return res\n",
    "\n",
    "# Contextual Word Embeddings Augmenter #\n",
    "# Substitute word by contextual word embeddings\n",
    "def substitute_contextual_word_embeddings_augmenter(text):\n",
    "    print('Substitute Contextual Word Embeddings Augmenter...')\n",
    "    context = naw.ContextualWordEmbsAug(\n",
    "        model_path='bert-base-uncased', action=\"substitute\"\n",
    "    )\n",
    "    res = context.augment(text)\n",
    "    return res\n",
    "\n",
    "\n",
    "# Synonym Augmenter #\n",
    "# Substitute word by WordNet's synonym\n",
    "def synonym_augmenter(text):\n",
    "    print('Synonym Augmenter...')\n",
    "    aug = naw.SynonymAug(aug_src='wordnet')\n",
    "    augmented_text = aug.augment(text)\n",
    "    return augmented_text\n",
    "\n",
    "\n",
    "# Antonym Augmenter #\n",
    "# Substitute word by antonym\n",
    "def antonym_augmenter(text):\n",
    "    print('Antonym Augmenter...')\n",
    "    aug = naw.AntonymAug()\n",
    "    augmented_text = aug.augment(text)\n",
    "    return augmented_text\n",
    "\n",
    "\n",
    "# Random Word Augmenter #\n",
    "# Swap word randomly\n",
    "def swap_random_word_augmenter(text):\n",
    "    print('Swap Random Word Augmenter...')\n",
    "    aug = naw.RandomWordAug(action=\"swap\")\n",
    "    augmented_text = aug.augment(text)\n",
    "    return augmented_text\n",
    "\n",
    "# Random Word Augmenter #\n",
    "# Delete word randomly\n",
    "def delete_random_word_augmenter(text):\n",
    "    print('Delete Random Word Augmenter...')\n",
    "    aug = naw.RandomWordAug()\n",
    "    augmented_text = aug.augment(text)\n",
    "    return augmented_text"
   ]
  },
  {
   "source": [
    "3. Sentence Augmenters (augmenters that work on sentence level)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contextual Word Embeddings #\n",
    "# Insert sentence by contextual word embeddings\n",
    "def contextual_word_embeddings_sentence_augmenter(text):\n",
    "    print('Contextual Word Embeddings for Sentence Augmenter...')\n",
    "    aug = nas.ContextualWordEmbsForSentenceAug(model_path='gpt2', )\n",
    "    augmented_text = aug.augment(text)\n",
    "    return augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(X, labels, is_train_data):\n",
    "    X_augmented = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    augmenters = [\n",
    "        keyboard_augmenter,\n",
    "        spelling_augmenter,\n",
    "        # insert_contextual_word_embeddings_augmenter, \n",
    "        # substitute_contextual_word_embeddings_augmenter,\n",
    "        # synonym_augmenter,\n",
    "        # antonym_augmenter,\n",
    "        # swap_random_word_augmenter,\n",
    "        # delete_random_word_augmenter,\n",
    "        # contextual_word_embeddings_sentence_augmenter\n",
    "    ]\n",
    "\n",
    "    print('Augmenting', 'training data' if is_train_data else 'test data', '\\n')\n",
    "\n",
    "    if is_train_data:\n",
    "        for idx, example in enumerate(X.to_list()):\n",
    "            if labels[idx] in [0, 1, 4]:\n",
    "                for augmenter in augmenters:\n",
    "                    augmented_example = augmenter(example)[:2]\n",
    "                    X_augmented.extend(augmented_example)\n",
    "                    augmented_labels.extend([labels[idx] for _ in range(len(augmented_example))])\n",
    "            else:\n",
    "                for augmenter in augmenters:\n",
    "                    augmented_example = [augmenter(example)[0]]\n",
    "                    X_augmented.extend(augmented_example)\n",
    "                    augmented_labels.extend([labels[idx] for _ in range(len(augmented_example))])\n",
    "    else:\n",
    "        for idx, example in enumerate(X.to_list()):\n",
    "            if labels.to_list()[idx] in [0, 1, 4]:\n",
    "                for augmenter in augmenters:\n",
    "                    augmented_example = [augmenter(example)[0]]\n",
    "                    X_augmented.extend(augmented_example)\n",
    "                    augmented_labels.extend([labels.to_list()[idx] for _ in range(len(augmented_example))])\n",
    "            # else:\n",
    "            #     for augmenter in augmenters:\n",
    "            #         augmented_example = [augmenter(example)[0]]\n",
    "            #         X.extend(augmented_example)\n",
    "            #         augmented_labels.extend([labels.to_list()[idx] for _ in range(len(augmented_example))])\n",
    "\n",
    "\n",
    "\n",
    "    X = X.to_list()\n",
    "    X.extend(X_augmented)\n",
    "    print('X data after augmentation:', len(X))\n",
    "\n",
    "    labels = labels.tolist()\n",
    "    labels.extend(augmented_labels)\n",
    "    print('Labels data after augmentation:',len(labels))\n",
    "\n",
    "    # Count augmented data by class\n",
    "    count = {\n",
    "        0: 0,\n",
    "        1: 0,\n",
    "        2: 0,\n",
    "        3: 0,\n",
    "        4: 0,\n",
    "    }\n",
    "\n",
    "    for i in labels:\n",
    "        count[i] += 1\n",
    "\n",
    "    print('-'*34)\n",
    "    print(' constructive feedback/idea |', count[0])\n",
    "    print(' negative', ' '*17 ,  '|', count[1])\n",
    "    print(' neutral/other', ' '*12 ,  '|', count[2])\n",
    "    print(' positive', ' '*17 ,  '|', count[3])\n",
    "    print(' sadness', ' '*18 ,  '|', count[4])\n",
    "    print('-'*34)\n",
    "\n",
    "    return X, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = augment_data(X_train, y_train, is_train_data=True)\n",
    "X_test, y_test = augment_data(X_test, y_test, is_train_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train:', len(X_train), '|', 'X_test:', len(X_test))\n",
    "print('y_train:', len(y_train), '|', 'y_test:', len(y_test))"
   ]
  },
  {
   "source": [
    "### Tokenizer and Encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased', use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode data\n",
    "X_train_encoded = tokenizer(X_train, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "X_test_encoded = tokenizer(X_test.to_list(), truncation=True, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "source": [
    "### Training and Testing Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "train_data = torch.utils.data.TensorDataset(\n",
    "    X_train_encoded['input_ids'], \n",
    "    X_train_encoded['attention_mask'],\n",
    "    torch.tensor(y_train)\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=8,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Testing Data\n",
    "test_data = torch.utils.data.TensorDataset(\n",
    "    X_test_encoded['input_ids'], \n",
    "    X_test_encoded['attention_mask'],\n",
    "    torch.tensor(y_test.to_list())\n",
    ")\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=8,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=N_EMOTIONS)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "source": [
    "# Hyper-parameters Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cifar(config, train_loader=None, test_loader=None):\n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=N_EMOTIONS)\n",
    "    # CUDA and parallel training (if available)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    # if torch.cuda.device_count() > 1:\n",
    "    #     model = nn.DataParallel(model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=config['lr'], correct_bias=False)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=config['num_warmup_steps'], num_training_steps=len(train_loader)*10)\n",
    "\n",
    "    print('Training...')\n",
    "    for epoch in range(5):\n",
    "        print('Epoch:', epoch+1)\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in tqdm(train_loader):\n",
    "            # Zero model gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Get input data and move them to device\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "\n",
    "            # Predict\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            # Get loss, calculate and clip gradients, and update parameters\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            # Update scheduler\n",
    "            scheduler.step()\n",
    "            # Update total loss\n",
    "            total_loss += loss\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        print('Loss:', avg_train_loss.item())\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    val_steps = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            # Get data and move them to the right device\n",
    "            text, attention, labels = data\n",
    "            text, attention, labels = text.to(device), attention.to(device), labels.to(device)\n",
    "            # Get predictions from model\n",
    "            outputs = model(text, attention)\n",
    "            # Store predictions for batch size\n",
    "            predictions = []\n",
    "            for output in outputs.logits:\n",
    "                _, predicted = torch.max(output, 0)\n",
    "                predictions.append(predicted.item())\n",
    "            predictions = torch.tensor(predictions).to(device)\n",
    "            # Calculate total\n",
    "            total += labels.size(0)\n",
    "            # Calculate number of correct classification\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            # Calculate loss\n",
    "            print('Predictions', predictions)\n",
    "            print('Labels', labels)\n",
    "            loss = criterion(predictions, labels)\n",
    "            print('Loss', loss)\n",
    "            val_loss += loss.cpu().numpy()\n",
    "            val_steps += 1\n",
    "            print('Val loss', loss)\n",
    "\n",
    "\n",
    "        tune.report(loss=(val_loss/val_steps), accuracy=correct/total)\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HYPERPARAMETERS_TUNING:\n",
    "    # Hyper-parameters configuration\n",
    "    config = {\n",
    "        'lr': tune.loguniform(1e-6, 1e-1),\n",
    "        'batch_size': tune.choice([2, 4, 8,]),\n",
    "        'num_warmup_steps': tune.choice([0, 100, 200, 500])\n",
    "    }\n",
    "\n",
    "    # ASHAScheduler terminates bad performing trials early\n",
    "    asha_scheduler = ASHAScheduler(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            max_t=5,\n",
    "            grace_period=1,\n",
    "            reduction_factor=2\n",
    "    )\n",
    "\n",
    "    reporter = CLIReporter(metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "\n",
    "    result = tune.run(\n",
    "        partial(train_cifar, train_loader=train_dataloader, test_loader=test_dataloader),\n",
    "        resources_per_trial={ \"cpu\": 1, \"gpu\": 1 },\n",
    "        config=config,\n",
    "        num_samples=5,\n",
    "        scheduler=asha_scheduler,\n",
    "        progress_reporter=reporter,\n",
    "    )"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty CUDA cache\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_summary(device=device, abbreviated=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "EPOCHS = 10\n",
    "\n",
    "# Model on training mode\n",
    "model.train()\n",
    "# Define optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader)*EPOCHS)\n",
    "\n",
    "# Training loop\n",
    "print('Training...\\n')\n",
    "for epoch in range(EPOCHS):\n",
    "    print('-'*100)\n",
    "    print('Epoch:', epoch+1)\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        # Zero model gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Get input data and move them to device\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "\n",
    "        # Predict\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        # Get loss, calculate and clip gradients, and update parameters\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        # Update total loss\n",
    "        total_loss += loss\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print('Loss:', avg_train_loss.item())\n",
    "    print('-'*100)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "source": [
    "# Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model on CUDA\n",
    "model = model.to(device)\n",
    "# Model on evaluation mode\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "predicted_all = []\n",
    "true_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        # Get data and move them to the right device\n",
    "        text, attention, labels = data\n",
    "        text, attention, labels = text.to(device), attention.to(device), labels.to(device)\n",
    "        # Get predictions from model\n",
    "        outputs = model(text, attention)\n",
    "        # Store predictions for batch size\n",
    "        predictions = []\n",
    "        for output in outputs.logits:\n",
    "            _, predicted = torch.max(output, 0)\n",
    "            predictions.append(predicted.item())\n",
    "        predictions = torch.tensor(predictions).to(device)\n",
    "        # Calculate total\n",
    "        total += labels.size(0)\n",
    "        # Calculate number of correct classification\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        # Store all predictions and labels\n",
    "        predicted_all.extend(predictions.tolist())\n",
    "        true_all.extend(labels.tolist())\n",
    "\n",
    "print(f'Testing accuracy: {(100 * correct / total)}%')"
   ]
  },
  {
   "source": [
    "### F-1 Score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The closer to 1.0 the better\n",
    "sklearn.metrics.f1_score(predicted_all, true_all, average='weighted')"
   ]
  },
  {
   "source": [
    "### Cohen's Kappa statistic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bad model: less than 0.60\n",
    "# Good model: 0.60-0.80\n",
    "# Excellent: more than 0.80\n",
    "sklearn.metrics.cohen_kappa_score(predicted_all, true_all)"
   ]
  },
  {
   "source": [
    "### Plot correctly and incorrectly classified examples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_predicted_decoded = list(map(lambda x: decode_map[x], predicted_all))\n",
    "kappa_true_decoded = list(map(lambda x: decode_map[x], true_all))\n",
    "res = {\n",
    "    'neutral/other': { 'correct': 0, 'not_correct': 0 },\n",
    "    'positive': { 'correct': 0, 'not_correct': 0 },\n",
    "    'negative': { 'correct': 0, 'not_correct': 0 },\n",
    "    'constructive feedback/idea': { 'correct': 0, 'not_correct': 0 },\n",
    "    'sadness': { 'correct': 0, 'not_correct': 0 }\n",
    "}\n",
    "\n",
    "for i in range(len(kappa_true_decoded)):\n",
    "    if kappa_true_decoded[i] == kappa_predicted_decoded[i]:\n",
    "        res[kappa_true_decoded[i]]['correct'] += 1\n",
    "    else:\n",
    "        res[kappa_true_decoded[i]]['not_correct'] += 1\n",
    "\n",
    "\n",
    "neutral_c = res['neutral/other']['correct']\n",
    "neutral_nc = res['neutral/other']['not_correct']\n",
    "\n",
    "positive_c = res['positive']['correct']\n",
    "positive_nc = res['positive']['not_correct']\n",
    "\n",
    "negative_c = res['negative']['correct']\n",
    "negative_nc = res['negative']['not_correct']\n",
    "\n",
    "constructive_c = res['constructive feedback/idea']['correct']\n",
    "constructive_nc = res['constructive feedback/idea']['not_correct']\n",
    "\n",
    "sadness_c = res['sadness']['correct']\n",
    "sadness_nc = res['sadness']['not_correct']\n",
    "\n",
    "\n",
    "print('='*102)\n",
    "print('|', ' '*21, '|', 'neutral/other', '|', 'positive', '|', 'negative', '|', 'constructive feedback/idea', '|', 'sadness', '|')\n",
    "print('|', '='*98, '|')\n",
    "print('|', 'correctly predicted  ', '|', neutral_c, ' '*10, '|', positive_c, ' '*5, '|', negative_c, ' '*5, '|', constructive_c, ' '*23, '|', sadness_c, ' '*4, '|')\n",
    "print('|', '='*98, '|')\n",
    "print('|', 'incorrectly predicted', '|', neutral_nc, ' '*10, '|', positive_nc, ' '*5, '|', negative_nc, ' '*5, '|', constructive_nc, ' '*23, '|', sadness_nc, ' '*4, '|')\n",
    "print('='*102)"
   ]
  },
  {
   "source": [
    "### Confusion Matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get confusion matrix\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(true_all, predicted_all)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(5, 5), dpi=100)\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\n",
    "sns.set(font_scale=2.5)\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap=cmap, cbar=False)"
   ]
  },
  {
   "source": [
    "# New Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"\n",
    "    Programming is yelling at a computer what to do in a made-up cyberlanguage and the computer ignoring what you said because you missed a comma.\n",
    "\"\"\"\n",
    "\n",
    "encoded_sentence = tokenizer(sentence, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "model = model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(encoded_sentence.input_ids, encoded_sentence.attention_mask)\n",
    "    prediction = np.argmax(prediction.logits)\n",
    "\n",
    "decode_map[prediction.item()]"
   ]
  },
  {
   "source": [
    "# Save Model and Tokenizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('/tmp/model')\n",
    "tokenizer.save_pretrained('/tmp/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
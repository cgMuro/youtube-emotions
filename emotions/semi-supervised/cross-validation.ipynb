{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# Filter out all TensorFlow INFO and WARNING messages\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "source": [
    "# Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/labeled/youtube_labeled.csv', usecols=['text', 'emotion'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text']\n",
    "y = df['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOTIONS = df['emotion'].unique()\n",
    "N_EMOTIONS = len(EMOTIONS)\n",
    "N_EMOTIONS"
   ]
  },
  {
   "source": [
    "### Categorical"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_map = {\n",
    "    0: 'constructive feedback/idea',\n",
    "    1: 'negative',\n",
    "    2: 'neutral/other', \n",
    "    3: 'positive', \n",
    "    4: 'sadness', \n",
    "}"
   ]
  },
  {
   "source": [
    "# Model and Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to model in TensorFlow Hub\n",
    "model_hub_path = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\"\n",
    "\n",
    "\n",
    "# Build first module layers using TensorFlow Hub model\n",
    "hub_layer = hub.KerasLayer(model_hub_path, input_shape=[], dtype=tf.string, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# Define K-fold\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "fold_n = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(x):\n",
    "\n",
    "    # Define model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        hub_layer,\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(N_EMOTIONS, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_n} ...')\n",
    "\n",
    "    results = model.fit(\n",
    "        x[train_index],\n",
    "        y[train_index],\n",
    "        epochs=100,\n",
    "        batch_size=256,\n",
    "        verbose=0\n",
    "    )\n",
    "    scores = model.evaluate(x[test_index], y[test_index], verbose=0)\n",
    "    print(f'Score for fold {fold_n}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold\n",
    "    fold_n += 1\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "source": [
    "## Save Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model, './models/emotion_crossval.h5')"
   ]
  },
  {
   "source": [
    "# Test Model with New Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"“He’s a famous YouTube bounty hunter, who also fakes his bounty hunts” lmao\"\"\"\n",
    "\n",
    "prediction = np.argmax(model.predict(np.array([sentence])))\n",
    "\n",
    "decode_map[prediction]"
   ]
  }
 ]
}